## Redis 键值设计

<br>

### 优雅 Key

Redis 的 Key 虽然可以自定义，但最好遵循下面的几个最佳实践约定：

- 遵循基本格式：`[业务名称]:[数据名]:[id]`
- 长度不超过 44 字节
- 不包含特殊字符

更节省内存： key 是 string 类型，底层编码包含 int、embstr 和 raw 三种。embstr 在小于 44 字节使用，采用连续内存空间，内存占用更小。当字节数大于 44 字节时，会转为 raw 模式存储，在 raw 模式下，内存空间不是连续的，而是采用一个指针指向了另外一段内存空间，在这段空间里存储 SDS 内容，这样空间不连续，访问的时候性能也就会收到影响，还有可能产生内存碎片

<br>

### 请不要使用 BigKey

下面是几个 bigkey 可能存在的场景

- Key 本身的数据量过大：一个 String 类型的 Key，它的值为 5 MB
- Key 中的成员数过多：一个 ZSET 类型的 Key，它的成员数量为 10,000 个
- Key 中成员的数据量过大：一个 Hash 类型的 Key，它的成员数量虽然只有 1,000 个但这些成员的 Value（值）总大小为 100 MB

<br>

#### 检索 bigkey

使用 redis 自带指令检索：`redis-cli -a 密码 --bigkeys`

使用工具：Redis-Rdb-Tools 分析 RDB 快照文件，全面分析内存使用情况

<br>

#### 删除 bigkey

bigkey 本身体积就极大，再去删除的话必定占用线程资源，需要考虑清楚在做

Redis 在 4.0 后提供了异步删除的命令：unlink

<br>

### 合适的数据类型

存储一个对象的最佳方式是使用 Hash  
（但是对应的实现比较复杂）

且 `hash` 的 `entry` 数量超过 500 时，会使用哈希表而不是 ZipList，内存占用较多  
虽然可以使用 `hash-max-ziplist-entries` 配置 entry 上限，但是如果 entry 过多就会导致 BigKey 问题

<br>

解决 entry 过多的问题：

拆分为小的 hash，将 id / 100 作为 key， 将 id % 100 作为 field，这样每 100 个元素为一个 Hash

<br>

## 批处理优化

<br>

### Pipeline

对于批量插入数据的方法（如 MSET），可以直接批量插入

假如数据类型比较复杂，那么推荐改用 pipeline 实现

```java
@Test
void testPipeline() {
    // 创建管道
    Pipeline pipeline = jedis.pipelined();
    long b = System.currentTimeMillis();
    for (int i = 1; i <= 100000; i++) {
        // 放入命令到管道
        pipeline.set("test:key_" + i, "value_" + i);
        if (i % 1000 == 0) {
            // 每放入1000条命令，批量执行
            pipeline.sync();
        }
    }
    long e = System.currentTimeMillis();
    System.out.println("time: " + (e - b));
}
```

<br>

### 集群下的批处理

![](./img/r11.png)

Spring 集群环境下批处理代码

```java
   @Test
    void testMSetInCluster() {
        Map<String, String> map = new HashMap<>(3);
        map.put("name", "Rose");
        map.put("age", "21");
        map.put("sex", "Female");
        stringRedisTemplate.opsForValue().multiSet(map);


        List<String> strings = stringRedisTemplate.opsForValue().multiGet(Arrays.asList("name", "age", "sex"));
        strings.forEach(System.out::println);

    }
```

代码对应底层原理：

在 RedisAdvancedClusterAsyncCommandsImpl 类中

首先根据 slotHash 算出来一个 partitioned 的 map，map 中的 key 就是 slot，而他的 value 就是对应的对应相同 slot 的 key 对应的数据

<br>

## 服务端优化

建议遵循持久化协议：

- 用来做缓存的 Redis 实例尽量不要开启持久化功能
- 建议关闭 RDB 持久化功能，使用 AOF 持久化
- 利用脚本定期在 slave 节点做 RDB，实现数据备份
- 设置合理的 rewrite 阈值，避免频繁的 bgrewrite
- 配置 no-appendfsync-on-rewrite = yes，禁止在 rewrite 期间做 aof，避免因 AOF 引起的阻塞
- 部署有关建议：
- Redis 实例的物理机要预留足够内存，应对 fork 和 rewrite
- 单个 Redis 实例内存上限不要太大，例如 4G 或 8G。可以加快 fork 的速度、减少主从同步、数据迁移压力
- 不要与 CPU 密集型应用部署在一起
- 不要与高硬盘负载应用一起部署。例如：数据库、消息队列

<br>

## 慢查询优化

Redis 执行时耗时超过某个阈值的命令，称为慢查询。

<br>

### 慢查询配置

慢查询的阈值可以通过配置指定：

`slowlog-log-slower-than`：慢查询阈值，单位是微秒。默认是 10000，建议 1000

慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：

`slowlog-max-len`：慢查询日志（本质是一个队列）的长度。默认是 128，建议 1000

<br>

### 查看慢查询

知道了以上内容之后，那么咱们如何去查看慢查询日志列表呢：

- `slowlog len`：查询慢查询日志长度
- `slowlog get [n]`：读取 n 条慢查询日志
- `slowlog reset`：清空慢查询列表

<br>

### 安全配置

redis 默认绑定 IP 会使其暴露于公网，造成安全隐患

目前比较可行的一种方法是使用 SSH 公钥私钥加密：生成一对公钥和私钥，私钥放在本地，公钥放在 redis 端，当我们登录时服务器，再登录时候，他会去解析公钥和私钥，如果没有问题，则不需要利用 redis 的登录也能访问

<br>

### redis 内存划分配置

碎片问题：假定当前 key 只需要 10 个字节，此时分配 8 肯定不够，那么他就会分配 16 个字节，多出来的 6 个字节就不能被使用，这些就是碎片

#### 缓冲区问题

一般包括客户端缓冲区、AOF 缓冲区、复制缓冲区等。  
客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，所以这片内存也是我们需要重点分析的内存问题。

| **内存占用** | **说明**                                                                                                                                                  |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 数据内存     | 是 Redis 最主要的部分，存储 Redis 的键值信息。主要问题是 BigKey 问题、内存碎片问题                                                                        |
| 进程内存     | Redis 主进程本身运⾏肯定需要占⽤内存，如代码、常量池等等；这部分内存⼤约⼏兆，在⼤多数⽣产环境中与 Redis 数据占⽤的内存相⽐可以忽略。                     |
| 缓冲区内存   | 一般包括客户端缓冲区、AOF 缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用 BigKey，可能导致内存溢出。 |

<br>

#### 内存缓冲区

内存缓冲区常见的有三种：

- 复制缓冲区：主从复制的 repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过 replbacklog-size 来设置，默认 1mb
- AOF 缓冲区：AOF 刷盘之前的缓存区域，AOF 执行 rewrite 的缓冲区。无法设置容量上限
- 客户端缓冲区：分为输入缓冲区和输出缓冲区，输入缓冲区最大 1G 且不能设置。输出缓冲区可以设置

客户端缓冲区：指的就是我们发送命令时，客户端用来缓存命令的一个缓冲区，也就是我们向 redis 输入数据的输入端缓冲区和 redis 向客户端返回数据的响应缓存区。  
输入缓冲区最大 1G 且不能设置，如果超过了这个空间，redis 会直接断开，因为本来此时此刻就代表着 redis 处理不过来了

输出端缓冲区因为 redis 处理大数据的原因，有可能瞬间就会被填满而导致 redis 链接断开，此时有两种主流的解决办法

1. 设置一个大小
2. 增加我们带宽的大小，避免我们出现大量数据从而直接超过了 redis 的承受能力

<br>

## 集群还是主从？

集群使用并非 100%完美的，他目前存在以下问题：

- 集群完整性问题
- 集群带宽问题
- 数据倾斜问题
- 客户端性能问题
- 命令的集群兼容性问题
- lua 和事务问题

<br>

### 集群完整性问题

当部分 slot 无法使用了，会导致整个集群不可用，这对于开发是灾难性的

我们需要在配置文件将该选项改成 no，使得即便 slot 挂了，依然可以运行服务

<br>

### 集群带宽问题

集群节点之间会相互 ping 来保活，但如果节点过多，这些频繁的 ping 很可能会直接占满带宽

解决办法

- 避免大集群，集群节点数不要太多，最好少于 1000，如果业务庞大，则建立多个集群。
- 避免在单个物理机中运行太多 Redis 实例
- 配置合适的 cluster-node-timeout 值

<br>

### lua 和事务问题

lua 和事务都是要保证原子性问题，如果你的 key 不在一个节点，那么是无法保证 lua 的执行和事务的特性的，所以在集群模式是没有办法执行 lua 和事务的

<br>

### 集群 or 单体？

单体 Redis（主从 Redis）已经能达到万级别的 QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建 Redis 集群

<br>
